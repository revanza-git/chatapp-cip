# Google Colab + Ollama Configuration
# Copy this to .env after setting up your Colab notebook

# Frontend Configuration
NEXT_PUBLIC_API_URL=http://localhost:8080

# Backend Configuration
DATABASE_URL=postgresql://chatbot_user:chatbot_password@postgres:5432/chatbot_db
UPLOADS_DIR=uploads
SKIP_DATABASE=false

# Security
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production-minimum-32-characters

# AI Configuration - GOOGLE COLAB SETUP
AI_ENABLED=true
# Replace with your actual ngrok URL from Colab notebook
OLLAMA_URL=https://f2ed7f4b3f90.ngrok-free.app
# Keep HF token as backup
HF_TOKEN=your-hugging-face-token-here

# Server Configuration
PORT=8080
FRONTEND_URL=http://localhost:3000

# Instructions:
# 1. Run the Colab notebook: backend/colab_ollama_complete_setup.ipynb
# 2. Copy the ngrok URL from Cell 5 and update OLLAMA_URL above
# 3. Copy this file to .env: cp .env.colab .env
# 4. Start your backend: npm run start:dev
# 5. Your chatbot will use GPU-accelerated AI responses!
